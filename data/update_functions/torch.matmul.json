{
    "api_path": "torch.matmul",
    "arguments_str": "input,other,*,out=None",
    "doc_string": "matmul(input, other, *, out=None) -> Tensor\n\nMatrix product of two tensors.\n\nThe behavior depends on the dimensionality of the tensors as follows:\n\n- If both tensors are 1-dimensional, the dot product (scalar) is returned.\n- If both arguments are 2-dimensional, the matrix-matrix product is returned.\n- If the first argument is 1-dimensional and the second argument is 2-dimensional,\n  a 1 is prepended to its dimension for the purpose of the matrix multiply.\n  After the matrix multiply, the prepended dimension is removed.\n- If the first argument is 2-dimensional and the second argument is 1-dimensional,\n  the matrix-vector product is returned.\n- If both arguments are at least 1-dimensional and at least one argument is\n  N-dimensional (where N > 2), then a batched matrix multiply is returned.  If the first\n  argument is 1-dimensional, a 1 is prepended to its dimension for the purpose of the\n  batched matrix multiply and removed after.  If the second argument is 1-dimensional, a\n  1 is appended to its dimension for the purpose of the batched matrix multiple and removed after.\n  The non-matrix (i.e. batch) dimensions are :ref:`broadcasted <broadcasting-semantics>` (and thus\n  must be broadcastable).  For example, if :attr:`input` is a\n  :math:`(j \\times 1 \\times n \\times n)` tensor and :attr:`other` is a :math:`(k \\times n \\times n)`\n  tensor, :attr:`out` will be a :math:`(j \\times k \\times n \\times n)` tensor.\n\n  Note that the broadcasting logic only looks at the batch dimensions when determining if the inputs\n  are broadcastable, and not the matrix dimensions. For example, if :attr:`input` is a\n  :math:`(j \\times 1 \\times n \\times m)` tensor and :attr:`other` is a :math:`(k \\times m \\times p)`\n  tensor, these inputs are valid for broadcasting even though the final two dimensions (i.e. the\n  matrix dimensions) are different. :attr:`out` will be a :math:`(j \\times k \\times n \\times p)` tensor.\n\nThis operation has support for arguments with :ref:`sparse layouts<sparse-docs>`. In particular the\nmatrix-matrix (both arguments 2-dimensional) supports sparse arguments with the same restrictions\nas :func:`torch.mm`\n\n\n.. warning::\n    Sparse support is a beta feature and some layout(s)/dtype/device combinations may not be supported,\n    or may not have autograd support. If you notice missing functionality please\n    open a feature request.\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\n.. note::\n\n    The 1-dimensional dot product version of this function does not support an :attr:`out` parameter.\n\nArguments:\n    input (Tensor): the first tensor to be multiplied\n    other (Tensor): the second tensor to be multiplied\n\nKeyword args:\n    out (Tensor, optional): the output tensor.\n\nExample::\n\n    >>> # vector x vector\n    >>> tensor1 = torch.randn(3)\n    >>> tensor2 = torch.randn(3)\n    >>> torch.matmul(tensor1, tensor2).size()\n    torch.Size([])\n    >>> # matrix x vector\n    >>> tensor1 = torch.randn(3, 4)\n    >>> tensor2 = torch.randn(4)\n    >>> torch.matmul(tensor1, tensor2).size()\n    torch.Size([3])\n    >>> # batched matrix x broadcasted vector\n    >>> tensor1 = torch.randn(10, 3, 4)\n    >>> tensor2 = torch.randn(4)\n    >>> torch.matmul(tensor1, tensor2).size()\n    torch.Size([10, 3])\n    >>> # batched matrix x batched matrix\n    >>> tensor1 = torch.randn(10, 3, 4)\n    >>> tensor2 = torch.randn(10, 4, 5)\n    >>> torch.matmul(tensor1, tensor2).size()\n    torch.Size([10, 3, 5])\n    >>> # batched matrix x broadcasted matrix\n    >>> tensor1 = torch.randn(10, 3, 4)\n    >>> tensor2 = torch.randn(4, 5)\n    >>> torch.matmul(tensor1, tensor2).size()\n    torch.Size([10, 3, 5])",
    "imports": [
        "import torch"
    ],
    "return_type_hint": "-> Tensor",
    "source_code": null,
    "summarized_doc": "**Function**: matmul(input, other, *, out=None) -> Tensor\n\nThis function returns the matrix product of two tensors. The behaviour depends on the dimensions of the tensors. \n\n**Input Parameters**:\n\n- **input (Tensor)**: The first tensor to be multiplied.\n- **other (Tensor)**: The second tensor to be multiplied.\n\n**Keyword Args**:\n\n- **out (Tensor, optional)**: The output tensor. Note that there's no support for this parameter when calculating 1-dimensional dot product.\n\n**Output**:\n- **Returns a Tensor**.\n\n**Description**:\n- For both 1-dimensional tensors, it returns the dot product (scalar).\n- For both 2-dimensional tensors, it returns the matrix-matrix product.\n- For a 1-dimensional and a 2-dimensional tensor, it prepends a 1 to the dimension of the first tensor, performs the matrix multiplication, then removes the prepended dimension.\n- For a 2-dimensional and a 1-dimensional tensor, it returns the matrix-vector product.\n- For both tensors with 1 or more dimensions, where at least one has more than 2, it returns a batched matrix multiply. Here, it appends or prepends a 1 to the dimension depending on which tensor is 1-dimensional.\n  \n**Note**:\n\n1. Sparse support is a beta feature. It supports sparse arguments with the same restrictions as `torch.mm`.\n2. This operator supports `TensorFloat32`.\n3. There's a different precision for backward in ROCm devices when using float16 inputs.\n\n**Examples**:\n\n```\n>>> # vector x vector\n>>> tensor1 = torch.randn(3)\n>>> tensor2 = torch.randn(3)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([])\n>>> # matrix x vector\n>>> tensor1 = torch.randn(3, 4)\n>>> tensor2 = torch.randn(4)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([3])\n>>> # batched matrix x broadcasted vector\n>>> tensor1 = torch.randn(10, 3, 4)\n>>> tensor2 = torch.randn(4)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([10, 3])\n>>> # batched matrix x batched matrix\n>>> tensor1 = torch.randn(10, 3, 4)\n>>> tensor2 = torch.randn(10, 4, 5)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([10, 3, 5])\n>>> # batched matrix x broadcasted matrix\n>>> tensor1 = torch.randn(10, 3, 4)\n>>> tensor2 = torch.randn(4, 5)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([10, 3, 5])\n```"
}