defaults:
  - data: prepend
  - model: lora
  - generation: prepend
  - prompt: finetune
  - evaluation: default
  - training: lora
  - _self_


training: 
  batch_size: 8

model:
  model_name_or_path: # hf model id or path to model

data:
  data_dir: # hf dataset id or path to data
  training_example_per_update: 1
  test_example_per_update: 1

output_dir: tmp/chkpt_null  

prompt:
  train_source: prompts/instruction_style_ft_k_ps.jinja2
  eval_source: prompts/humaneval.jinja2

usage: 

seed: 42
debug: false
rerun_eval: false