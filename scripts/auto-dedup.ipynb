{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ast\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tiktoken\n",
    "import editdistance\n",
    "\n",
    "from itertools import chain\n",
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"openlm-research/code-llama-13b\")\n",
    "\n",
    "def extract_solution(fname):\n",
    "    with open(fname) as f:\n",
    "        content = f.read()\n",
    "\n",
    "    delimiter_ids = []\n",
    "    delimiter = \"# ---------------------------------\"\n",
    "    lines = content.split(\"\\n\")\n",
    "    for l_i, l in enumerate(lines):\n",
    "        if l.startswith(delimiter):\n",
    "            delimiter_ids.append(l_i)\n",
    "    assert len(delimiter_ids) == 2\n",
    "    s, e = delimiter_ids\n",
    "    fixed_solution = \"\\n\".join(lines[s+1:e])\n",
    "\n",
    "    return fixed_solution\n",
    "\n",
    "\n",
    "class CodeProcessor(ast.NodeTransformer):\n",
    "    def __init__(self, imported_packages):\n",
    "        self.var_counter = 0\n",
    "        self.var_mapping = {}\n",
    "        self.imported_packages = imported_packages\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        node.returns = None\n",
    "\n",
    "        # Anonymize variable names in function definition\n",
    "        self.anonymize_funcid(node)\n",
    "        node.args.args = [self.anonymize_arg(arg) for arg in node.args.args]\n",
    "        node.body = [self.visit(child) for child in node.body]\n",
    "\n",
    "        return node\n",
    "\n",
    "    def visit_Name(self, node):\n",
    "        # Anonymize variable names in function code\n",
    "        if isinstance(node.ctx, ast.Store):\n",
    "            return self.anonymize_name(node)\n",
    "        \n",
    "        if isinstance(node.ctx, ast.Load):\n",
    "            return self.anonymize_name(node)\n",
    "\n",
    "    def visit_arg(self, node):\n",
    "        # Remove type annotations from function arguments\n",
    "        node.annotation = None\n",
    "        return node\n",
    "\n",
    "    def visit_Return(self, node):\n",
    "        # Remove type annotations from return value\n",
    "        node.value = self.visit(node.value)\n",
    "        return node\n",
    "\n",
    "    def anonymize_funcid(self, node):\n",
    "        if node.name in self.imported_packages:\n",
    "            return node\n",
    "        if node.name not in self.var_mapping:\n",
    "            self.var_mapping[node.name] = f'var{self.var_counter}'\n",
    "            self.var_counter += 1\n",
    "        node.name = self.var_mapping[node.name]\n",
    "        return node\n",
    "\n",
    "    def anonymize_name(self, node):\n",
    "        if node.id in self.imported_packages:\n",
    "            return node\n",
    "        if node.id not in self.var_mapping:\n",
    "            self.var_mapping[node.id] = f'var{self.var_counter}'\n",
    "            self.var_counter += 1\n",
    "        node.id = self.var_mapping[node.id]\n",
    "        return node\n",
    "        \n",
    "    def anonymize_arg(self, arg):\n",
    "    \n",
    "        if arg.arg not in self.var_mapping:\n",
    "            self.var_mapping[arg.arg] = f'var{self.var_counter}'\n",
    "            self.var_counter += 1\n",
    "        arg.arg = self.var_mapping[arg.arg]\n",
    "        arg.annotation = None\n",
    "        return arg\n",
    "\n",
    "def extract_imports(code):\n",
    "    import_pattern = re.compile(r'import\\s+(\\w+(?:\\.\\w+)*)')\n",
    "    from_import_pattern = re.compile(r'from\\s+(\\w+(?:\\.\\w+)*)\\s+import\\s+')\n",
    "\n",
    "    imports = []\n",
    "    \n",
    "    # Extract 'import' statements\n",
    "    for match in import_pattern.finditer(code):\n",
    "        package = match.group(1)\n",
    "        imports.append(package)\n",
    "    \n",
    "    # Extract 'from ... import' statements\n",
    "    for match in from_import_pattern.finditer(code):\n",
    "        package = match.group(1)\n",
    "        imports.append(package)\n",
    "\n",
    "    return imports\n",
    "\n",
    "def process_code_ast(code):\n",
    "\n",
    "    tree = ast.parse(code)\n",
    "    imported_packages = extract_imports(code)\n",
    "\n",
    "    processor = CodeProcessor(imported_packages)\n",
    "    processed_tree = processor.visit(tree)\n",
    "    processed_code = ast.unparse(processed_tree)\n",
    "    return processed_code\n",
    "\n",
    "\n",
    "def tokenize_code(code):\n",
    "    # Load the \"code llama\" tokenizer\n",
    "    global tokenizer\n",
    "\n",
    "    # Tokenize the code string\n",
    "    tokens = tokenizer.tokenize(code)\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def tokenize_openai(code):\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    return encoding.encode(code)\n",
    "\n",
    "\n",
    "def dir_listing(dirs):\n",
    "    all_dirs = []\n",
    "    for d in dirs:\n",
    "        dirs_of_d = os.listdir(d)\n",
    "        dirs_of_d = [os.path.join(d, x) for x in dirs_of_d if not x.startswith(\".\")]\n",
    "        all_dirs.extend(dirs_of_d)\n",
    "    return all_dirs\n",
    "\n",
    "\n",
    "def dedup_single_update(update_dir):\n",
    "    # sub_dirs = os.listdir(update_dir)\n",
    "    # sub_dirs = [os.path.join(update_dir, x) for x in sub_dirs if not x.startswith(\".\")]\n",
    "    # update_files = [os.path.join(x, \"ref_solution.py\") for x in sub_dirs]\n",
    "    update_files = dir_listing(dir_listing([update_dir]))\n",
    "\n",
    "    orig_codes = []\n",
    "    prog_codes = []\n",
    "    for fname in update_files:\n",
    "        solution = extract_solution(fname)\n",
    "        orig_codes.append(solution)\n",
    "        try:\n",
    "            proc_solution = process_code_ast(solution)\n",
    "        except:\n",
    "            proc_solution =  solution\n",
    "\n",
    "        prog_codes.append(proc_solution)\n",
    "\n",
    "    similarity_pairs = []\n",
    "    num_prog = len(prog_codes)\n",
    "    for i in range(num_prog):\n",
    "        file_a, orig_a, prog_a = update_files[i], orig_codes[i], prog_codes[i]\n",
    "        tok_prog_a = tokenize_openai(prog_a)\n",
    "        for j in range(i + 1, num_prog):\n",
    "            file_b, orig_b, prog_b = update_files[j], orig_codes[j], prog_codes[j]\n",
    "            tok_prog_b = tokenize_openai(prog_b)\n",
    "\n",
    "            similarity_pairs.append({\n",
    "                    \"file_a\": file_a,\n",
    "                    \"orig_a\": orig_a,\n",
    "                    \"proc_a\": prog_a,\n",
    "                    \"file_b\": file_b,\n",
    "                    \"orig_b\": orig_b,\n",
    "                    \"proc_b\": prog_b,\n",
    "                    \"distance\": editdistance.eval(tok_prog_a, tok_prog_b)\n",
    "                })\n",
    "\n",
    "    return similarity_pairs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "THRESHOLD = 5 # make a threshold\n",
    "target_dedup_dir = \"/u/zliu/tool-KE/data/prelim/dedup_Xi\"\n",
    "update_dirs = dir_listing(dir_listing(dir_listing([target_dedup_dir])))\n",
    "\n",
    "# handle update one by one\n",
    "all_sim_pairs = []\n",
    "for update_dir in update_dirs:\n",
    "    all_sim_pairs.extend(dedup_single_update(update_dir))\n",
    "all_sim_pairs = sorted(all_sim_pairs, key=lambda x: x[\"distance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = np.arange(0, len(all_sim_pairs))\n",
    "np.random.shuffle(sample_ids)\n",
    "sample_ids = sample_ids[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(all_sim_pairs))\n",
    "from scipy.stats import describe\n",
    "print(describe([p[\"distance\"] for p in all_sim_pairs]))\n",
    "median_edit_dist = np.median(([p[\"distance\"] for p in all_sim_pairs]))\n",
    "\n",
    "print(np.median(([p[\"distance\"] for p in all_sim_pairs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_sim_pairs = [all_sim_pairs[i] for i in sample_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in sampled_sim_pairs[:10]:\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Dist\", p[\"distance\"])\n",
    "        print(\"Prog A:\", p[\"file_a\"])\n",
    "        # print(\"ORIGINAL\")\n",
    "        # print(p[\"orig_a\"])\n",
    "        print(\"CANONICALIZED\")\n",
    "        print(p[\"proc_a\"])\n",
    "        print(\"Prog B:\", p[\"file_b\"])\n",
    "        # print(\"ORIGINAL\")\n",
    "        # print(p[\"orig_b\"])\n",
    "        print(\"CANONICALIZED\")\n",
    "        print(p[\"proc_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in all_sim_pairs[:]:\n",
    "        if p[\"distance\"] >= 25:\n",
    "                continue\n",
    "        print(\"-\" * 10)\n",
    "        print(\"Dist\", p[\"distance\"])\n",
    "        print(\"Prog A:\", p[\"file_a\"])\n",
    "        # print(\"ORIGINAL\")\n",
    "        # print(p[\"orig_a\"])\n",
    "        print(\"CANONICALIZED\")\n",
    "        print(p[\"proc_a\"])\n",
    "        print(\"Prog B:\", p[\"file_b\"])\n",
    "        # print(\"ORIGINAL\")\n",
    "        # print(p[\"orig_b\"])\n",
    "        print(\"CANONICALIZED\")\n",
    "        print(p[\"proc_b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_ps_distri = np.array([p[\"distance\"] for p in all_sim_pairs if p[\"distance\"] >= 25 ])\n",
    "values, bins, bars = plt.hist(num_ps_distri, bins=50, ec=\"k\", rwidth=1)\n",
    "\n",
    "# num_ps_distri = np.array(unit_tests_pass_w_updates)\n",
    "# values, bins, bars = plt.hist(num_ps_distri, ec=\"k\")\n",
    "# plt.xticks(np.arange(num_ps_distri.min(), num_ps_distri.max()+1, 20))\n",
    "import seaborn as sns\n",
    "sns.set_palette(\"tab10\")\n",
    "# plt.bar_label(bars)\n",
    "plt.xlabel(\"Edit Distance\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Edit Distance of Canonicalized Solutions\")\n",
    "plt.savefig(\"<save dir>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 25\n",
    "from collections import Counter, defaultdict\n",
    "len([p[\"distance\"] for p in all_sim_pairs if p['distance'] < threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = 14\n",
    "upper = lower + 10\n",
    "\n",
    "for p in [p for p in all_sim_pairs if lower < p['distance'] < upper]:\n",
    "    prog_syn_id_a = \"/\".join(p[\"file_a\"].split(\"/\")[-5:-1])\n",
    "    specific_update_id_a = \"/\".join(p[\"file_a\"].split(\"/\")[-5:-2])\n",
    "    \n",
    "    print(\"-\" * 10)\n",
    "    print(\"Dist\", p[\"distance\"])\n",
    "    print(\"Prog A:\", p[\"file_a\"])\n",
    "    # print(\"ORIGINAL\")\n",
    "    # print(p[\"orig_a\"])\n",
    "    print(\"CANONICALIZED\")\n",
    "    print(p[\"proc_a\"])\n",
    "    prog_syn_id_b = \"/\".join(p[\"file_b\"].split(\"/\")[-5:-1])\n",
    "    specific_update_id_b = \"/\".join(p[\"file_b\"].split(\"/\")[-5:-2])\n",
    "    assert prog_syn_id_a != prog_syn_id_b\n",
    "    assert specific_update_id_a == specific_update_id_b\n",
    "    print(\"Prog B:\", p[\"file_b\"])\n",
    "    # print(\"ORIGINAL\")\n",
    "    # print(p[\"orig_b\"])\n",
    "    print(\"CANONICALIZED\")\n",
    "    print(p[\"proc_b\"])\n",
    "print(len([p for p in all_sim_pairs if lower < p['distance'] < upper]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semifinal_data_root = \"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-PS\"\n",
    "all_update_paths = list(glob.glob(f\"{semifinal_data_root}/**/update-content-w_ut.json\", recursive=True))\n",
    "update2ps = {}\n",
    "PS_FILE_NAME = \"prog_syn-content-w_ut.json\"\n",
    "U_FILE_NAME = \"update-content-w_ut.json\"\n",
    "\n",
    "for update_path in all_update_paths:\n",
    "    update_dir = os.path.dirname(update_path)\n",
    "    specific_update_id = \"/\".join(update_dir.split(\"/\")[-3:])\n",
    "    api, update_type, _ = specific_update_id.split(\"/\")\n",
    "    \n",
    "    update_ps_paths = list(glob.glob(f\"{update_dir}/**/{PS_FILE_NAME}\", recursive=True))\n",
    "    update2ps[specific_update_id] = update_ps_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(len(vs) for vs in update2ps.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human min: 24 \n",
    "from collections import defaultdict, Counter\n",
    "threshold = 25\n",
    "a = [p for p in all_sim_pairs if p['distance'] < threshold]\n",
    "np.random.shuffle(a)\n",
    "dup_update2ps_graph = defaultdict(lambda: defaultdict(set))\n",
    "dup_update2ps_pairs = defaultdict(set)\n",
    "dup_update2ps = defaultdict(set)\n",
    "edit_distance_df = []\n",
    "\n",
    "for p in a:\n",
    "    prog_syn_id_a = \"/\".join(p[\"file_a\"].split(\"/\")[-5:-1])\n",
    "    specific_update_id_a = \"/\".join(p[\"file_a\"].split(\"/\")[-5:-2])\n",
    "    \n",
    "    # print(\"-\" * 10)\n",
    "    # print(\"Dist\", p[\"distance\"])\n",
    "    # print(\"Prog A:\", p[\"file_a\"])\n",
    "    # print(\"ORIGINAL\")\n",
    "    # print(p[\"orig_a\"])\n",
    "    # print(\"CANONICALIZED\")\n",
    "    # print(p[\"proc_a\"])\n",
    "    prog_syn_id_b = \"/\".join(p[\"file_b\"].split(\"/\")[-5:-1])\n",
    "    specific_update_id_b = \"/\".join(p[\"file_b\"].split(\"/\")[-5:-2])\n",
    "    assert prog_syn_id_a != prog_syn_id_b\n",
    "    assert specific_update_id_a == specific_update_id_b\n",
    "    # print(\"Prog B:\", p[\"file_b\"])\n",
    "    # print(\"ORIGINAL\")\n",
    "    # print(p[\"orig_b\"])\n",
    "    # print(\"CANONICALIZED\")\n",
    "    # print(p[\"proc_b\"])\n",
    "\n",
    "    # if prog_syn_id_a in dup_update2ps[specific_update_id_a] or prog_syn_id_b in dup_update2ps[specific_update_id_a][prog_syn_id_a]:\n",
    "    #     # assert prog_syn_id_b not in dup_update2ps[specific_update_id_a]\n",
    "    #     dup_update2ps[specific_update_id_a][prog_syn_id_a].add(prog_syn_id_b)\n",
    "    # elif prog_syn_id_b in dup_update2ps[specific_update_id_a]:\n",
    "    #     dup_update2ps[specific_update_id_a][prog_syn_id_b].add(prog_syn_id_a)\n",
    "    # else:\n",
    "    #     dup_update2ps[specific_update_id_a][prog_syn_id_a].add(prog_syn_id_b)\n",
    "    dup_update2ps_graph[specific_update_id_a][prog_syn_id_a].add(prog_syn_id_b)\n",
    "    dup_update2ps[specific_update_id_a].add(prog_syn_id_a)\n",
    "    dup_update2ps[specific_update_id_a].add(prog_syn_id_b)\n",
    "    dup_update2ps_pairs[specific_update_id_a].add((prog_syn_id_a, prog_syn_id_b, p[\"distance\"]))\n",
    "    # dup_update2ps[specific_update_id_a][prog_syn_id_b]\n",
    "    # dup_update2ps[specific_update_id_a].add(prog_syn_id_b)\n",
    "# dup_update2ps = {k: list(v) for k, v in dup_update2ps.items()}\n",
    "print(\"original #PS:\")\n",
    "num_ps2count = dict(Counter(len(update2ps[specific_update]) for specific_update in dup_update2ps_pairs.keys()))\n",
    "print(num_ps2count)\n",
    "ps_threshold = 5\n",
    "print(f\"Count(#PS > {ps_threshold})\")\n",
    "print(sum(v for k, v in num_ps2count.items() if k > ps_threshold))\n",
    "print(f\"Count(#PS <= {ps_threshold})\")\n",
    "print(sum(v for k, v in num_ps2count.items() if k <= ps_threshold))\n",
    "\n",
    "import itertools\n",
    "dedup_update2ps_graph = {}\n",
    "count_below_x = 0\n",
    "x = 2\n",
    "non_dup_update = 0\n",
    "update2dedup_count = {}\n",
    "update2dedup_ps = {}\n",
    "dup_update2dedup_count = {}\n",
    "dup_update2original_count = {}\n",
    "update2new_ps = {}\n",
    "dup_update2dedup_ps = {}\n",
    "legal_dup_distances = []\n",
    "for specific_update_id, dup_ps_pairs in dup_update2ps_pairs.items():\n",
    "    ps = [\"/\".join(p.split(\"/\")[-5:-1]) for p in update2ps[specific_update_id]]\n",
    "    assert len(set(ps)) == len(ps)\n",
    "    ps = set(ps)\n",
    "    dup_update2original_count[specific_update_id] = len(ps)\n",
    "    unique_dup_ps = set(itertools.chain(*[[a, b] for a,b,d in dup_ps_pairs]))\n",
    "    dup_update2ps[specific_update_id] = unique_dup_ps\n",
    "    \n",
    "    dup_update2dedup_count[specific_update_id] = len(ps) - len(unique_dup_ps)\n",
    "    update2dedup_ps[specific_update_id] = dup_update2dedup_ps[specific_update_id] = ps - unique_dup_ps\n",
    "    \n",
    "    if len(update2dedup_ps[specific_update_id]) == 0 or len(update2dedup_ps[specific_update_id]) > 2:\n",
    "        continue\n",
    "    \n",
    "    sorted_by_distance = sorted(dup_ps_pairs, key=lambda x: x[-1])\n",
    "    p_1, p_2, distance = sorted_by_distance[-1]\n",
    "    legal_dup_distances.append(distance)\n",
    "    \n",
    "    update2dedup_ps[specific_update_id] |= set([p_1, p_2])\n",
    "    \n",
    "print(f\"Total duplicate #PS: {sum(len(v) for v in update2dedup_ps.values())}\")\n",
    "\n",
    "for specific_update_id, ps in update2ps.items():\n",
    "    if specific_update_id in update2dedup_ps:\n",
    "        continue\n",
    "    update2dedup_ps[specific_update_id] = [\"/\".join(p.split(\"/\")[-5:-1]) for p in ps]\n",
    "update2dedup_ps = {k: vs for k, vs in update2dedup_ps.items() if len(vs) > 0}\n",
    "print(f\"#Update After: {len(update2dedup_ps)}\")\n",
    "print(f\"Total #PS after dedup {sum([len(vs) for vs in update2dedup_ps.values()])}\")\n",
    "print(f\"#PS demo before dedupe: {Counter([len(vs) for vs in update2ps.values()])}\")\n",
    "print(f\"#PS demo after dedupe: {Counter([len(vs) for vs in update2dedup_ps.values()])}\")\n",
    "import matplotlib.pyplot as plt\n",
    "num_ps_distri = np.array([len(vs) for vs in update2dedup_ps.values()])\n",
    "values, bins, bars = plt.hist(num_ps_distri, ec=\"k\", rwidth=1)\n",
    "\n",
    "# num_ps_distri = np.array(unit_tests_pass_w_updates)\n",
    "# values, bins, bars = plt.hist(num_ps_distri, ec=\"k\")\n",
    "# plt.xticks(np.arange(num_ps_distri.min(), num_ps_distri.max()+1, 20))\n",
    "\n",
    "plt.bar_label(bars)\n",
    "plt.xlabel(\"Pass w. Update (during generation)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Pass w. Update  distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = []\n",
    "\n",
    "# for update, ps_ids in update2dedup_ps.items():\n",
    "#     api, update_type, _ = update.split(\"/\")\n",
    "#     pacakge = api.split(\".\")[0]\n",
    "#     if len(update_type.split(\"-\")) == 2:\n",
    "#         action, place = update_type.split(\"-\")\n",
    "#         aspect = None\n",
    "#     else:\n",
    "#         assert len(update_type.split(\"-\")) == 3\n",
    "#         action, place, aspect = update_type.split(\"-\")\n",
    "    \n",
    "#     df.append({\n",
    "#         \"pacakge\": pacakge,\n",
    "#         \"api\": api,\n",
    "#         \"update_type\": update_type,\n",
    "#         \"[action]\": action,\n",
    "#         \"[locus]\": place,\n",
    "#         \"[aspect]\": aspect,\n",
    "#         \"[locus]-[aspect]\": f\"{place}-{aspect}\",\n",
    "#         \"#PS\": len(ps_ids)\n",
    "#     })\n",
    "# df = pd.DataFrame(df)\n",
    "all_ps_paths = glob.glob(f\"<save root for prog syn>/**/{PS_FILE_NAME}\", recursive=True)\n",
    "all_ps_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ps_paths[0].split(\"/\")[-5:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "def is_testing_try_catch(unit_test):\n",
    "    return all(x in unit_test for x in [\"try:\",  \"except\"])\n",
    "\n",
    "progsyn_df = []\n",
    "gpt4_tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "all_ps_paths = glob.glob(f\"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-dedup/**/{PS_FILE_NAME}\", recursive=True)\n",
    "for ps_path in all_ps_paths:\n",
    "    api, update_type, _, _ = ps_path.split(\"/\")[-5:-1]\n",
    "    update_id = \"/\".join(ps_path.split(\"/\")[-5:-2])\n",
    "    progsyn_id = \"/\".join(ps_path.split(\"/\")[-5:-1])\n",
    "    \n",
    "    update_path = \"/\".join(ps_path.split(\"/\")[:-2]) + \"/\" + U_FILE_NAME\n",
    "    assert os.path.exists(update_path)\n",
    "    \n",
    "    pacakge = api.split(\".\")[0]\n",
    "    if len(update_type.split(\"-\")) == 2:\n",
    "        action, place = update_type.split(\"-\")\n",
    "        aspect = None\n",
    "    else:\n",
    "        assert len(update_type.split(\"-\")) == 3\n",
    "        action, place, aspect = update_type.split(\"-\")\n",
    "    ps_content = json.load(open(ps_path, \"r\"))\n",
    "    update_content = json.load(open(update_path, \"r\"))\n",
    "    \n",
    "    progsyn_df.append({\n",
    "        \"update_id\": update_id,\n",
    "        \"progsyn_id\": progsyn_id,\n",
    "        \"package\": pacakge,\n",
    "        \"api\": api,\n",
    "        \"update_type\": update_type,\n",
    "        \"[action]\": action,\n",
    "        \"[locus]\": place,\n",
    "        \"[aspect]\": aspect,\n",
    "        \"[locus]-[aspect]\": f\"{place}-{aspect}\",\n",
    "        \"#token(update docstring)\": len(gpt4_tokenizer.encode(update_content[\"update_docstring\"])),\n",
    "        # \"#token(update implementation)\": len(gpt4_tokenizer.encode(update_content[\"new_impl\"])),\n",
    "        # \"Avg. #token(update unit test)\": np.mean([len(gpt4_tokenizer.encode(u)) for u in update_content[\"unit_tests\"] if not is_testing_try_catch(u)]),\n",
    "        # \"#update_unit_tests\": len([u for u in update_content[\"unit_tests\"] if not is_testing_try_catch(u)]),\n",
    "        \"#token(scenario)\": len(gpt4_tokenizer.encode(ps_content[\"scenario\"])),\n",
    "        \"#token(problem)\": len(gpt4_tokenizer.encode(ps_content[\"problem\"])),\n",
    "        \"#token(reference solution)\": len(gpt4_tokenizer.encode(ps_content[\"solution_new\"])),\n",
    "        \"Avg. #token(prog_syn unit test)\": np.mean([len(gpt4_tokenizer.encode(u)) for u in ps_content[\"unit_tests\"] if not is_testing_try_catch(u)]),\n",
    "        \"#progsyn_unit_tests\": len([u for u in ps_content[\"unit_tests\"] if not is_testing_try_catch(u)]),\n",
    "    })\n",
    "progsyn_df = pd.DataFrame(progsyn_df)\n",
    "progsyn_df.to_csv(\"<save dir>/prog-syn-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_ps_distri = np.array([int(x) for x in progsyn_df.groupby(\"update_id\").describe()[\"#token(scenario)\"][\"count\"].to_list()])\n",
    "values, bins, bars = plt.hist(num_ps_distri, ec=\"k\", rwidth=1)\n",
    "\n",
    "# num_ps_distri = np.array(unit_tests_pass_w_updates)\n",
    "# values, bins, bars = plt.hist(num_ps_distri, ec=\"k\")\n",
    "# plt.xticks(np.arange(num_ps_distri.min(), num_ps_distri.max()+1, 20))\n",
    "\n",
    "plt.bar_label(bars)\n",
    "plt.xlabel(\"#PS\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"#PS / update\")\n",
    "plt.savefig(\"/u/zliu/tool-KE/plot_neurips/histogram-ps-per-update.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "def is_testing_try_catch(unit_test):\n",
    "    return all(x in unit_test for x in [\"try:\",  \"except\"])\n",
    "\n",
    "update_df = []\n",
    "gpt4_tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "\n",
    "all_update_paths = glob.glob(f\"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-dedup/**/{U_FILE_NAME}\", recursive=True)\n",
    "for update_path in all_update_paths:\n",
    "    api, update_type, _ = update_path.split(\"/\")[-4:-1]\n",
    "    update_id = \"/\".join(update_path.split(\"/\")[-4:-1])\n",
    "    \n",
    "    pacakge = api.split(\".\")[0]\n",
    "    if len(update_type.split(\"-\")) == 2:\n",
    "        action, place = update_type.split(\"-\")\n",
    "        aspect = None\n",
    "    else:\n",
    "        assert len(update_type.split(\"-\")) == 3\n",
    "        action, place, aspect = update_type.split(\"-\")\n",
    "    update_content = json.load(open(update_path, \"r\"))\n",
    "    update_df.append({\n",
    "        \"update_id\": update_id,\n",
    "        \"package\": pacakge,\n",
    "        \"api\": api,\n",
    "        \"update_type\": update_type,\n",
    "        \"[action]\": action,\n",
    "        \"[locus]\": place,\n",
    "        \"[aspect]\": aspect,\n",
    "        \"[locus]-[aspect]\": f\"{place}-{aspect}\",\n",
    "        \"#token(update docstring)\": len(gpt4_tokenizer.encode(update_content[\"update_docstring\"])),\n",
    "        \"#token(update implementation)\": len(gpt4_tokenizer.encode(update_content[\"new_impl\"])),\n",
    "        \"Avg. #token(update unit test)\": np.mean([len(gpt4_tokenizer.encode(u)) for u in update_content[\"unit_tests\"]]),\n",
    "        \"#update_unit_tests\": len([u for u in update_content[\"unit_tests\"]]),\n",
    "        # \"#token(scenario)\": len(gpt4_tokenizer.encode(ps_content[\"scenario\"])),\n",
    "        # \"#token(problem)\": len(gpt4_tokenizer.encode(ps_content[\"problem\"])),\n",
    "        # \"#token(reference solution)\": len(gpt4_tokenizer.encode(ps_content[\"solution_new\"])),\n",
    "        # \"Avg. #token(prog_syn unit test)\": np.mean([len(gpt4_tokenizer.encode(u)) for u in ps_content[\"unit_tests\"] if not is_testing_try_catch(u)]),\n",
    "        # \"#progsyn_unit_tests\": len([u for u in ps_content[\"unit_tests\"] if not is_testing_try_catch(u)]),\n",
    "    })\n",
    "update_df = pd.DataFrame(update_df)\n",
    "update_df.to_csv(\"/u/zliu/tool-KE/tables/update-summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scipy.stats import describe\n",
    "from collections import Counter\n",
    "describe(list(Counter([p for p, a in update_df.groupby([\"package\", \"api\"]).describe().index]).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_df[\"#update_unit_tests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"#token(reference solution)\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"api\").describe()[\"#token(update docstring)\"][\"count\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sizes = list(zip(*Counter(df[\"update_type\"]).items()))\n",
    "palette_color = sns.color_palette(\"colorblind\") \n",
    "  \n",
    "# plotting data on chart \n",
    "plt.pie(sizes, labels=labels, colors=palette_color, autopct='%.0f%%')\n",
    "plt.savefig(\"/u/zliu/tool-KE/plot_neurips/pie-chart-by-update-type.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sizes = list(zip(*Counter(df[\"package\"]).items()))\n",
    "palette_color = sns.color_palette(\"colorblind\") \n",
    "  \n",
    "# plotting data on chart \n",
    "plt.pie(sizes, labels=labels, colors=palette_color, autopct='%.0f%%')\n",
    "plt.savefig(\"/u/zliu/tool-KE/plot_neurips/pie-chart-by-package.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe(legal_dup_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(legal_dup_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "ps2unit_tests = {}\n",
    "def is_testing_try_catch(unit_test):\n",
    "    return all(x in unit_test for x in [\"try:\",  \"except\"])\n",
    "        \n",
    "update2try = defaultdict(set)\n",
    "n_test_threshold = 3\n",
    "\n",
    "for specific_update_id, dedup_ps in update2dedup_ps.items():\n",
    "    for ps_id in dedup_ps:\n",
    "        \n",
    "        assert os.path.exists(f\"{semifinal_data_root}/{ps_id}/{PS_FILE_NAME}\")\n",
    "        ps_content = json.load(open(f\"{semifinal_data_root}/{ps_id}/{PS_FILE_NAME}\", \"r\"))\n",
    "        unit_tests = ps_content[\"unit_tests\"]\n",
    "        pass_w_update = ps_content[\"unit_tests_pass_w_update\"]\n",
    "        trimmed_unit_tests = [unit_tests[int(i)] for i, pass_flag in pass_w_update.items() if pass_flag]\n",
    "        # remove unit tests that are testing try catch\n",
    "        trimmed_unit_tests = [u for u in trimmed_unit_tests if not is_testing_try_catch(u)]\n",
    "        if len(trimmed_unit_tests) < n_test_threshold:\n",
    "            update2try[specific_update_id].add(ps_id)\n",
    "        ps2unit_tests[ps_id] = trimmed_unit_tests\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"#UnitTest demographics {Counter(len(vs) for vs in ps2unit_tests.values())}\")\n",
    "print(f\"#PS removed {sum(len(vs) for vs in update2try.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many updates are we left with if we remove those things\n",
    "update2detry = {}\n",
    "for specific_update_id, dedup_ps in update2dedup_ps.items():\n",
    "    try_ps = update2try[specific_update_id]\n",
    "    assert len(set(dedup_ps)) == len(dedup_ps)\n",
    "    update2detry[specific_update_id] = set(dedup_ps) - try_ps\n",
    "print(f\"#Update removed: {sum(len(vs) < 3 for vs in update2detry.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pass(pass_dict):\n",
    "    return all(pass_dict.values())\n",
    "def accuracy(pass_dict):\n",
    "    return np.mean(list(pass_dict.values()))\n",
    "def pass_at_k(n: int, c: int, k: int):\n",
    "    \"\"\"\n",
    "    :param n: total number of samples\n",
    "    :param c: number of correct samples\n",
    "    :param k: k in pass@$k$\n",
    "    \"\"\"\n",
    "    if n - c < k: return 1.0 \n",
    "    return 1.0 - np.prod(1.0 - k / np.arange(n - c + 1, n + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(test_reports[1].pass_w_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(test_reports[1].pass_w_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ps_after_dedup = set(itertools.chain(*update2dedup_ps.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_ps_after_dedup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_test_reports_wo_trycatch(test_reports, exclude_trycatch=False, min_unit_tests=None):\n",
    "    c_old_excl = 0\n",
    "    c_new_excl = 0\n",
    "    c_unsolved = 0\n",
    "    c_old = 0\n",
    "    c_new = 0\n",
    "\n",
    "    n = len(test_reports)\n",
    "\n",
    "    accuracies = []\n",
    "    affected = []\n",
    "    ids = []\n",
    "    if exclude_trycatch:\n",
    "        ids = [idx for idx, contain_try_catch in enumerate([is_testing_try_catch(u) for u in test_reports[0].unit_tests.values()]) if contain_try_catch]\n",
    "        \n",
    "    if exclude_trycatch and \\\n",
    "        min_unit_tests is not None and \\\n",
    "            (len(test_reports[0].unit_tests.values()) - len(ids) < min_unit_tests):\n",
    "        return None\n",
    "    \n",
    "    from copy import deepcopy\n",
    "    for test_report in test_reports:\n",
    "        pass_w_update = deepcopy(test_report.pass_w_update)\n",
    "        pass_wo_update = deepcopy(test_report.pass_wo_update)\n",
    "        if exclude_trycatch:\n",
    "            for idx in ids:\n",
    "                del pass_w_update[idx]\n",
    "                del pass_wo_update[idx]\n",
    "        \n",
    "        c_old_excl += all_pass(pass_wo_update) and not all_pass(pass_w_update)\n",
    "        c_new_excl += all_pass(pass_w_update) and not all_pass(pass_wo_update)\n",
    "        c_old += all_pass(pass_wo_update)\n",
    "        c_new += all_pass(pass_w_update)\n",
    "        \n",
    "        affected.append(sum(pass_w_update.values()) != sum(pass_wo_update.values()))\n",
    "        accuracies.append(accuracy(pass_w_update))\n",
    "        \n",
    "    \n",
    "    c_unsolved = n - c_old_excl - c_new_excl\n",
    "    ret = {\"n_test\": len(test_reports[0].unit_tests) - len(ids)}\n",
    "    ret[f\"unsolved (%)\"] = c_unsolved / n * 100\n",
    "    for k in [1,2,5]:\n",
    "        # ret[f\"{prefix}_pass@{k}\"] = np.nan if n == 0 or c > n else pass_at_k(n, c, k)\n",
    "        ret[f\"pass@{k}(new)\"] = np.nan if n == 0 or c_new > n else pass_at_k(n, c_new, k) * 100\n",
    "        ret[f\"UPass@{k}\"] = np.nan if n == 0 or c_new_excl > n else pass_at_k(n, c_new_excl, k) * 100\n",
    "        \n",
    "        ret[f\"pass@{k}(old)\"] = np.nan if n == 0 or c_old > n else pass_at_k(n, c_old, k) * 100\n",
    "\n",
    "        ret[f\"pass@{k}(old excl.)\"] = np.nan if n == 0 or c_old_excl > n else pass_at_k(n, c_old_excl, k) * 100\n",
    "    ret[\"affected\"] = np.mean(affected) * 100\n",
    "    ret[\"accuracies\"] = np.mean(accuracies) * 100\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "[\"gpt-4\", \"deepseek-coder-7b-instruct-v1.5\", \"CodeLlama-7b-Instruct-hf\", \"deepseek-coder-6.7b-instruct\"]\n",
    "# based on update2detry recalculate GPT-4 results\n",
    "prepend_result_root = \"/u/zliu/tool-KE/evaluation_output/prepend_n=5\"\n",
    "REPORT_FILE_NAME = \"test_reports.pkl\"\n",
    "model_name = \"gpt-4\"\n",
    "all_report_paths = list(glob.glob(f\"{prepend_result_root}/**/{model_name}/{REPORT_FILE_NAME}\", recursive=True))\n",
    "\n",
    "\n",
    "def recal_df(report_paths, dedup=False, ps_after_dedup=set(), exclude_trycatch=False, min_unit_tests=None):\n",
    "    all_eval_results = []\n",
    "    for report_path in report_paths:\n",
    "        test_reports = pickle.load(open(report_path, \"rb\"))\n",
    "        eval_result = aggregate_test_reports_wo_trycatch(test_reports, exclude_trycatch=exclude_trycatch, min_unit_tests=min_unit_tests)\n",
    "        if eval_result is None:\n",
    "            continue\n",
    "        \n",
    "        prog_syn_id = \"/\".join(report_path.split(\"/\")[-6:-2])\n",
    "        if dedup and prog_syn_id not in ps_after_dedup:\n",
    "            continue\n",
    "        \n",
    "        specific_update_id = \"/\".join(report_path.split(\"/\")[-6:-3])\n",
    "        api_path, update_type, _ = specific_update_id.split(\"/\")\n",
    "        \n",
    "        if len(update_type.split(\"-\")) == 3:\n",
    "            action, location, aspect = update_type.split(\"-\")\n",
    "        else:\n",
    "            assert len(update_type.split(\"-\")) == 2\n",
    "            action, location = update_type.split(\"-\")\n",
    "            aspect = None\n",
    "        all_eval_results.append(eval_result)\n",
    "        eval_result[\"api_path\"] = api_path\n",
    "        eval_result[\"update_type\"] = update_type\n",
    "        eval_result[\"[location]-[aspect]\"] = f\"{location}-{aspect}\"\n",
    "        eval_result[\"[action]\"] = f\"{action}\"\n",
    "        eval_result[\"model\"] = f\"{model_name}\"\n",
    "        \n",
    "        eval_result[\"package\"] = api_path.split(\".\")[0]\n",
    "        eval_result[\"specific_update_id\"] = specific_update_id\n",
    "        eval_result[\"prog_syn_id\"] = prog_syn_id\n",
    "    \n",
    "    df = pd.DataFrame(all_eval_results)\n",
    "    df = df.reset_index().drop([\"index\"], axis=1) # .set_index([\"package\", \"api_path\", \"update_type\", \"specific_update_id\", \"prog_syn_id\"]).drop([\"index\"], axis=1)\n",
    "    num_update = 0\n",
    "    for specific_update_id, sub_df in df.groupby(['specific_update_id']):\n",
    "        if len(sub_df) >= 3:\n",
    "            num_update += 1\n",
    "    print(f\"#Update: {num_update}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 682.000000 - 608.000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recal_df(all_report_paths, dedup=False, ps_after_dedup=all_ps_after_dedup, exclude_trycatch=False, min_unit_tests=None).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_table = recal_df(list(glob.glob(f\"/u/zliu/tool-KE/evaluation_output_dedup/prepend_n=5/**/gpt-4/{REPORT_FILE_NAME}\", recursive=True)), \n",
    "         dedup=False, ps_after_dedup=all_ps_after_dedup, exclude_trycatch=True, min_unit_tests=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table = recal_df(list(glob.glob(f\"/u/zliu/tool-KE/evaluation_output_dedup/prepend_n=5/**/gpt-4/{REPORT_FILE_NAME}\", recursive=True)), \n",
    "         dedup=False, ps_after_dedup=all_ps_after_dedup, exclude_trycatch=True, min_unit_tests=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tunable_model_names = [\"deepseek-coder-7b-instruct-v1.5\", \"CodeLlama-7b-Instruct-hf\", \"deepseek-coder-6.7b-instruct\"]\n",
    "model_name = tunable_model_names[2]\n",
    "recal_df(list(glob.glob(f\"/u/zliu/tool-KE/evaluation_output_dedup/FT-2_n=5/**/{model_name}/{REPORT_FILE_NAME}\", recursive=True)), \n",
    "         dedup=False, ps_after_dedup=all_ps_after_dedup, exclude_trycatch=False, min_unit_tests=3).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table[:258].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table[final_table[\"package\"] == \"torch\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sizes = list(zip(*Counter(final_table[\"update_type\"]).items()))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sizes = list(zip(*Counter(final_table[\"package\"]).items()))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[\"gpt-4\", \"deepseek-coder-7b-instruct-v1.5\", \"CodeLlama-7b-Instruct-hf\", \"deepseek-coder-6.7b-instruct\"]\n",
    "model_name = \"deepseek-coder-6.7b-instruct\"\n",
    "recal_df(list(glob.glob(f\"{prepend_result_root}/**/{model_name}/{REPORT_FILE_NAME}\", recursive=True)), \n",
    "         dedup=True, ps_after_dedup=all_ps_after_dedup, exclude_trycatch=True, min_unit_tests=3).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/\".join(all_failed_prog_syns[0].split(\"/\")[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(f\"{semifinal_data_root}/{all_failed_prog_syns[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_failed_prog_syns = final_table[final_table[\"pass@5(new)\"] == 0][\"prog_syn_id\"].to_list()\n",
    "# get update arena bigger than certain size\n",
    "semifinal_data_root = \"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-PS\"\n",
    "prepend_result_root = \"/u/zliu/tool-KE/evaluation_output/prepend_n=5\"\n",
    "# all_update_paths = list(glob.glob(f\"{semifinal_data_root}/**/update-content-w_ut.json\", recursive=True))\n",
    "from src.utils.prompt_tool import CodeGenTemplate, InstructTemplate\n",
    "from omegaconf import OmegaConf\n",
    "from data.prelim.manager_update import UpdateManagerV21\n",
    "from data.prelim.manager_prog_syn import ProgSynManagerV21\n",
    "\n",
    "PS_FILE_NAME = \"prog_syn-content-w_ut.json\"\n",
    "U_FILE_NAME = \"update-content-w_ut.json\"\n",
    "ps_target_root = \"/u/zliu/tool-KE/data/prelim/gpt4_failed\"\n",
    "\n",
    "\n",
    "update_cfg = OmegaConf.load(\"configs/update_generation_v2-1.yaml\")\n",
    "update_cfg.new_impl.include_unit_tests=True\n",
    "\n",
    "progsyn_cfg = OmegaConf.load(\"configs/prog_syn_generation_v2-1.yaml\")\n",
    "\n",
    "delimiter = \"# ---------------------------------\"\n",
    "\n",
    "os.makedirs(ps_target_root, exist_ok=True)\n",
    "\n",
    "for prog_syn_id in all_failed_prog_syns:\n",
    "    \n",
    "    specific_update_id = \"/\".join(prog_syn_id.split(\"/\")[:-1])\n",
    "    update_dir = f\"{semifinal_data_root}/{specific_update_id}\"\n",
    "    api, update_type, _ = specific_update_id.split(\"/\")\n",
    "    \n",
    "    update_content = json.load(open(f\"{update_dir}/{U_FILE_NAME}\", \"r\"))\n",
    "    u_manager = UpdateManagerV21(cfg=update_cfg, api_path=api, update_tag=update_type)\n",
    "    u_manager.load_from_dir(save_dir=update_dir,)\n",
    "    update_info = [\n",
    "        (k, update_content[k].replace(\"\\n\", \"\\n#\")) \n",
    "        for k in \n",
    "        [\"update_description\", \"rationale\",\n",
    "        \"new_function_signature\", \"update_docstring\"]\n",
    "    ]\n",
    "    # new_impl = \"\\n\".join([l for l in update_content[\"new_impl\"].split(\"\\n\") if not l.strip().startswith(\"#\")])\n",
    "    new_impl = update_content[\"new_impl\"]\n",
    "    \n",
    "    ps_save_dir = f\"{semifinal_data_root}/{prog_syn_id}\"\n",
    "    ps_target_dir = f\"{ps_target_root}/{prog_syn_id}\"\n",
    "    os.makedirs(ps_target_dir, exist_ok=True)\n",
    "    \n",
    "    # assert len(list(glob.glob(f\"{ps_target_dir}/**/*solution.py\", recursive=True))) == 0\n",
    "    \n",
    "    assert os.path.exists(f\"{ps_save_dir}/{PS_FILE_NAME}\")\n",
    "    ps_content = json.load(open(f\"{ps_save_dir}/{PS_FILE_NAME}\", \"r\"))\n",
    "    unit_tests_pass_w_update = [ps_content[\"unit_tests_pass_w_update\"][str(i)] for i in range(len(ps_content[\"unit_tests_pass_w_update\"]))]\n",
    "    overall_pass_w_update = np.mean(unit_tests_pass_w_update)\n",
    "    \n",
    "    ps_info = [\n",
    "        (k, ps_content[k].replace(\"\\n\", \"\\n#\")) \n",
    "        for k in \n",
    "        [\"scenario\", \"problem\",\n",
    "        \"solution_signature\",]\n",
    "    ]\n",
    "    \n",
    "    # solution_new_no_comment = \"\\n\".join([l for l in ps_content[\"solution_new\"].split(\"\\n\") if not l.strip().startswith(\"#\")])\n",
    "    unit_tests = ps_content[\"unit_tests\"]\n",
    "    # trimmed_unit_tests = [unit_tests[int(i)] for i, pass_flag in ps_content[\"unit_tests_pass_w_update\"].items() if pass_flag]\n",
    "    # try_catch_unit_test_ids = [idx for idx, contain_try_catch in enumerate([is_testing_try_catch(u) for u in test_reports[0].unit_tests.values()]) if contain_try_catch]\n",
    "    # remove unit tests that are testing try catch\n",
    "    \n",
    "    solution_header = [\n",
    "        \"\\n\".join(ps_content[\"imports\"]),\n",
    "        \"\\n\".join([f\"\"\"# \"{k}\": {v}\"\"\"\n",
    "                        for k, v in update_info]),\n",
    "        new_impl,\n",
    "        u_manager.update_enforce_statement,\n",
    "        \"\\n\".join([f\"\"\"# \"{k}\": {v}\"\"\"\n",
    "                        for k, v in ps_info]),\n",
    "        f\"# PS path: {ps_save_dir}\",\n",
    "    ]\n",
    "    solution_trail = [\n",
    "        f\"# Overall pass_w_update (gen.) {overall_pass_w_update}\",\n",
    "        \"# Unit tests\",\n",
    "        *[\"\\n\".join([f\"# Unit test {i}\", f\"# pass_w_updates (gen.): {unit_tests_pass_w_update[i]}\", unit_test]) \n",
    "        for i, unit_test in enumerate(unit_tests) if not is_testing_try_catch(unit_test) and unit_tests_pass_w_update[i]],\n",
    "    ]\n",
    "    ref_solution_file = solution_header + [\n",
    "        f\"# Reference solution\",\n",
    "        delimiter,\n",
    "        ps_content[\"solution_new\"],\n",
    "        delimiter,\n",
    "    ] + solution_trail\n",
    "    open(f\"{ps_target_dir}/ref_solution.py\", \"w\").write(\"\\n\\n\".join(ref_solution_file))\n",
    "    \n",
    "    generated_texts = json.load(open(f\"{prepend_result_root}/{prog_syn_id}/gpt-4/generated_texts.json\", \"r\"))\n",
    "    test_reports = pickle.load(open(f\"{prepend_result_root}/{prog_syn_id}/gpt-4/test_reports.pkl\", \"rb\"))\n",
    "    generated_programs = list(map(InstructTemplate.solution_extractor, generated_texts))\n",
    "    \n",
    "    \n",
    "    for p_i, generated_program in enumerate(generated_programs):\n",
    "        test_report = test_reports[p_i]\n",
    "        overall_pass_w_update = np.mean([test_report.pass_w_update[i] for i, unit_test in test_report.unit_tests.items() if not is_testing_try_catch(unit_test)])\n",
    "        \n",
    "        solution_trail = [\n",
    "            f\"# Overall pass_w_update (gen.) {overall_pass_w_update}\",\n",
    "            \"# Unit tests\",\n",
    "            *[\"\\n\".join([\n",
    "                f\"# Unit test {i}\", \n",
    "                f\"# pass_w_updates (experiment): {test_report.pass_w_update[i]}\", \n",
    "                f\"# pass_wo_updates (experiment): {test_report.pass_wo_update[i]}\",\n",
    "                unit_test\n",
    "            ]) for i, unit_test in test_report.unit_tests.items() if not is_testing_try_catch(unit_test)\n",
    "            ],\n",
    "        ]\n",
    "        predict_solution_file = solution_header + [\n",
    "            f\"# Reference solution\",\n",
    "            delimiter,\n",
    "            generated_program,\n",
    "            delimiter,\n",
    "        ] + solution_trail\n",
    "        open(f\"{ps_target_dir}/predicted_solution-{p_i}.py\", \"w\").write(\"\\n\\n\".join(predict_solution_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(final_table[final_table[\"pass@5(new)\"] == 0][\"specific_update_id\"].to_list()))\n",
    "# [ps_content[\"unit_tests_pass_w_update\"][str(i)] for i in range(len(ps_content[\"unit_tests_pass_w_update\"]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.prompt_tool import CodeGenTemplate, InstructTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_programs = list(map(InstructTemplate.solution_extractor, generated_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semifinal_data_root = \"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-PS\"\n",
    "all_update_paths = list(glob.glob(f\"{semifinal_data_root}/**/update-content-w_ut.json\", recursive=True))\n",
    "update2ps_id = {}\n",
    "PS_FILE_NAME = \"prog_syn-content-w_ut.json\"\n",
    "U_FILE_NAME = \"update-content-w_ut.json\"\n",
    "\n",
    "for update_path in all_update_paths:\n",
    "    update_dir = os.path.dirname(update_path)\n",
    "    specific_update_id = \"/\".join(update_dir.split(\"/\")[-3:])\n",
    "    api, update_type, _ = specific_update_id.split(\"/\")\n",
    "    \n",
    "    update_ps_paths = list(glob.glob(f\"{update_dir}/**/{PS_FILE_NAME}\", recursive=True))\n",
    "    update2ps_id[specific_update_id] = set([\"/\".join(p.split(\"/\")[-5:-1]) for p in update_ps_paths])\n",
    "    assert len(update_ps_paths) == len(update2ps_id[specific_update_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update2ps_id['math.sin/modify-output-semantics/update-0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_table[\"prog_syn_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_update2dedup_ps = defaultdict(set)\n",
    "for prog_syn_id in final_table[\"prog_syn_id\"].to_list():\n",
    "    specific_update_id = \"/\".join(prog_syn_id.split(\"/\")[:-1])\n",
    "    final_update2dedup_ps[specific_update_id].add(prog_syn_id)\n",
    "final_update2dedup_ps = {k: vs for k, vs in final_update2dedup_ps.items() if len(vs) >= 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe([len(vs) for vs in final_update2dedup_ps.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_update_id = 'math.sin/modify-output-semantics/update-0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_update2dedup_ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([len(vs) for vs in final_update2dedup_ps.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copyanything(src, dst):\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.copytree(src, dst, dirs_exist_ok=True)\n",
    "    except OSError as exc: # python >2.5\n",
    "        if exc.errno in (errno.ENOTDIR, errno.EINVAL):\n",
    "            shutil.copy(src, dst)\n",
    "        else: raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semifinal_data_root = \"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-PS\"\n",
    "dedup_data_root = \"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-dedup\"\n",
    "\n",
    "old_expr_dir = \"/u/zliu/tool-KE/evaluation_output/prepend_n=5\"\n",
    "new_expr_dir = \"/u/zliu/tool-KE/evaluation_output_dedup/prepend_n=5\"\n",
    "\n",
    "source_root = semifinal_data_root\n",
    "target_root = dedup_data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update2ps_shrink_map = {}\n",
    "import shutil\n",
    "for specific_update_id in final_update2dedup_ps.keys():\n",
    "    assert os.path.exists(f\"{source_root}/{specific_update_id}/{U_FILE_NAME}\")\n",
    "    \n",
    "    os.makedirs(f\"{target_root}/{specific_update_id}\", exist_ok=True)\n",
    "    shutil.copyfile(f\"{source_root}/{specific_update_id}/{U_FILE_NAME}\", f\"{target_root}/{specific_update_id}/{U_FILE_NAME}\")\n",
    "    \n",
    "    remaining_ps = sorted(\n",
    "        final_update2dedup_ps[specific_update_id],\n",
    "        key=lambda x: int(x.split(\"-\")[-1])\n",
    "    )\n",
    "    \n",
    "    reindexed_remaining_ps = [f\"{specific_update_id}/ProgSyn-{i}\" for i in range(len(remaining_ps))]\n",
    "    ps_shrink_map = dict(zip(remaining_ps, reindexed_remaining_ps))\n",
    "    update2ps_shrink_map[specific_update_id] = ps_shrink_map\n",
    "    \n",
    "    for old_ps_dir, new_ps_dir in ps_shrink_map.items():\n",
    "        assert os.path.exists(f\"{target_root}/{new_ps_dir}\")\n",
    "        # os.makedirs(f\"{target_root}/{new_ps_dir}\", exist_ok=True)\n",
    "        # copyanything(f\"{source_root}/{old_ps_dir}\", f\"{target_root}/{new_ps_dir}\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(update2ps_shrink_map, open(f\"{dedup_data_root}/update2ps_shrink_map.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedup_data_root = \"/u/zliu/tool-KE/data/prelim/CodeUpdateArena-after-dedup\"\n",
    "all_update_paths = list(glob.glob(f\"{dedup_data_root}/**/{U_FILE_NAME}\", recursive=True))\n",
    "all_update_ids = [\"/\".join(p.split(\"/\")[-4:-1]) for p in all_update_paths]\n",
    "assert len(all_update_ids) == len(set(all_update_ids))\n",
    "len(all_update_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# random_ids = np.arange(len(all_update_ids))\n",
    "# np.random.shuffle(random_ids)\n",
    "sorted(random_ids[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_update_ids = [all_update_ids[i] for i in sorted(random_ids[:50])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(sampled_update_ids, open(\"/u/zliu/tool-KE/evaluation_output_dedup/specificity/sampled_update_ids.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for update_id in all_update_ids:\n",
    "    if update_id not in update2ps_shrink_map:\n",
    "        print(update_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "num_ps_distri = np.array([p for p in dedupe_update2ps.values()])\n",
    "values, bins, bars = plt.hist(num_ps_distri, bins=10, ec=\"k\", rwidth=0.6)\n",
    "\n",
    "# num_ps_distri = np.array(unit_tests_pass_w_updates)\n",
    "# values, bins, bars = plt.hist(num_ps_distri, ec=\"k\")\n",
    "# plt.xticks(np.arange(num_ps_distri.min(), num_ps_distri.max()+1, 20))\n",
    "\n",
    "plt.bar_label(bars)\n",
    "plt.xlabel(\"Pass w. Update (during generation)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Pass w. Update  distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool-ke",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
